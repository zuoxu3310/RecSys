{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean version available at:  \n",
    "- https://github.com/Personalization-Technologies-Lab/RecSys-Course-HSE-Fall23/tree/main/Seminar4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing packages:\n",
    "```\n",
    "# polara\n",
    "pip install --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds, LinearOperator\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='white', context='paper')\n",
    "%config InlineBackend.figure_format = \"svg\"\n",
    "\n",
    "from polara import get_movielens_data\n",
    "\n",
    "from dataprep import transform_indices, leave_last_out, verify_time_split, reindex_data, generate_interactions_matrix\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_movielens_data(include_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_, holdout_ = leave_last_out(data, 'userid', 'timestamp')\n",
    "verify_time_split(training_, holdout_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, data_index = transform_indices(training_, 'userid', 'movieid')\n",
    "holdout = (\n",
    "    reindex_data(holdout_, data_index, filter_invalid=True)\n",
    "    .sort_values('userid')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    test_users = holdout[data_index['users'].name].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = data_description['users']\n",
    "seen_idx_mask = training[userid].isin(data_description['test_users'])\n",
    "testset = training[seen_idx_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svd_model(config, data, data_description):\n",
    "    source_matrix = ... # type your code here\n",
    "    ... # get item embeddings and singular values, mind ordering in descending order\n",
    "    return item_factors, singular_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_config = {'rank': 200}\n",
    "\n",
    "V, sigma = svd_params = build_svd_model(svd_config, training, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify orthogonality\n",
    "np.testing.assert_almost_equal(\n",
    "    V.T @ V,\n",
    "    np.eye(svd_config['rank']), decimal=14\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sigma).plot(title='Top singular values', xlabel='rank');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Shifted\" PureSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD of\n",
    "$$A=\\hat{A}_0+\\alpha \\boldsymbol{e}_M \\boldsymbol{e}_N^{\\top}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description['average_rating'] = data[data_description['feedback']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_shifted_model(config, data, data_description):\n",
    "    source_matrix = ... # type your code here\n",
    "    average_rating = data_description['average_rating']\n",
    "    centered_matrix = ... # type your code here\n",
    "\n",
    "    # define matvecs for the LinearOperator of the shifted matrix\n",
    "    def shifted_mv(v):\n",
    "        return ... # type your code here\n",
    "\n",
    "    def shifted_rmv(v):\n",
    "        return ... # type your code here\n",
    "\n",
    "    shifted_matrix = LinearOperator(\n",
    "        source_matrix.shape,\n",
    "        shifted_mv,\n",
    "        shifted_rmv\n",
    "    )\n",
    "    _, s, vt = svds(shifted_matrix, k=config['rank'])\n",
    "    sidx = np.argsort(-s)\n",
    "    singular_values = s[sidx]\n",
    "    item_factors = np.ascontiguousarray(vt[sidx, :].T)\n",
    "    return item_factors, singular_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_shift, sigma_shift = shifted_params = build_shifted_model(\n",
    "    svd_config,\n",
    "    training,\n",
    "    data_description\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.Series(sigma).plot(\n",
    "    title='Top singular values',\n",
    "    xlabel='rank',\n",
    "    label='source',\n",
    "    legend=True,\n",
    "    logy=True\n",
    ")\n",
    "pd.Series(sigma_shift).plot(\n",
    "    legend=True,\n",
    "    label='shifted',\n",
    "    ax=ax,\n",
    "    ls='--'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sompare top singular value against the estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated leading singular value\n",
    "training.rating.mean() * np.sqrt(data_description['n_users'] * data_description['n_items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computed leading singular value\n",
    "sigma_shift.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very close!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how singular values accumulate from the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_sigma_idx = np.arange(svd_config['rank'], 0, -1)\n",
    "ax = pd.Series(sigma[::-1]**2, index=rev_sigma_idx).cumsum().pow(0.5).plot(\n",
    "    title='',\n",
    "    xlabel='rank',\n",
    "    label='source',\n",
    "    legend=True,\n",
    "    logy=True\n",
    ")\n",
    "pd.Series(sigma_shift[::-1]**2, index=rev_sigma_idx).cumsum().pow(0.5).plot(\n",
    "    legend=True,\n",
    "    label='shifted',\n",
    "    ax=ax,\n",
    "    ls='--'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stop here for a moment. What are possible conclusions from this graph:\n",
    "1. we reduced approximation error\n",
    "2. seems like we'll need lower rank value, as most of the variation is already explained by the first singular triplet.\n",
    "\n",
    "Let's scrutinize a bit over these two conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, singular values indicate general reduction of error, which includes errors computed on unknown ratings. Let's check error only for known ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_train_rmse(item_factors, data, data_description):\n",
    "    source_matrix = ... # type your code here\n",
    "    predicted = puresvd_predict(source_matrix, item_factors)\n",
    "    true_ratings = ... # type your code here\n",
    "    return rmse(true_ratings, predicted)\n",
    "\n",
    "def puresvd_predict(source_matrix, item_factors):\n",
    "    nnz_user, nnz_item = source_matrix.nonzero()\n",
    "    predicted = ... # type your code here\n",
    "    return predicted\n",
    "\n",
    "def rmse(true_ratings, predicted):\n",
    "    return np.sqrt(np.power(true_ratings - predicted, 2).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PureSVD\n",
    "svd_rmse = compute_train_rmse(V, training, data_description)\n",
    "print(f'{svd_rmse=:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_train_rmse_shifted(item_factors, data, data_description):\n",
    "    source_matrix = generate_interactions_matrix(data, data_description, rebase_users=False)\n",
    "    predicted = shifted_predict(source_matrix, item_factors)\n",
    "    true_ratings = source_matrix.data\n",
    "    return rmse(true_ratings, predicted)\n",
    "\n",
    "def shifted_predict(source_matrix, item_factors):\n",
    "    nnz_user, nnz_item = source_matrix.nonzero()\n",
    "    average_rating = ... # type your code here\n",
    "    centered_matrix = ... # type your code here\n",
    "    predicted = ... # type your code here\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifted PureSVD\n",
    "shifted_rmse = compute_train_rmse_shifted(train_matrix, V_shift)\n",
    "print(f'{shifted_rmse=:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, an improvement is quite substantial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate with more relevant metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_model_scoring(params, testset, data_description):\n",
    "    item_factors, sigma = params\n",
    "    test_matrix = ... # type your code here\n",
    "    scores = ... # type your code here\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_scores = svd_model_scoring(svd_params, testset, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(svd_scores, testset, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_recs = topn_recommendations(svd_scores, topn=10)\n",
    "model_evaluate(svd_recs, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_model_scoring(params, testset, data_description):\n",
    "    item_factors, sigma = params\n",
    "    average_rating = data_description['average_rating']\n",
    "    test_matrix = generate_interactions_matrix(testset, data_description, rebase_users=True)\n",
    "    centered_matrix = ... # type your code here\n",
    "    scores = ... # type your code here\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_scores = shifted_model_scoring(\n",
    "    shifted_params,\n",
    "    testset,\n",
    "    data_description\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(shifted_scores, testset, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_recs = topn_recommendations(shifted_scores)\n",
    "model_evaluate(shifted_recs, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we improved RMSE loss almost by 2.5x, but lost in terms of HitRate by more than 1.5x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for a range of rank values,  as the models do not have to have the same rank for optimal quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid-search experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_metrics(params, testset, data_description, shifted=False):\n",
    "    '''Calculates evaluation metrics for SVD models.'''\n",
    "    scoring_func = shifted_model_scoring if shifted else svd_model_scoring\n",
    "     ... # implement recommendations generation pipeline here\n",
    "    return model_evaluate(recs, holdout, data_description)\n",
    "\n",
    "def truncate_svd_params(params, rank):\n",
    "    '''Truncates model parameters to specified rank value.'''\n",
    "    item_factors, sigma = params\n",
    "    assert rank <= len(sigma)\n",
    "    return item_factors[:, :rank], sigma[:rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_ranks = [b*2**i for i in range(7) for b in [2, 3]]\n",
    "\n",
    "svd_config = ... # type your code here\n",
    "\n",
    "puresvd_params = build_svd_model(svd_config, training, data_description)\n",
    "shifted_params = build_shifted_model(svd_config, training, data_description)\n",
    "\n",
    "puresvd_metrics = {}\n",
    "shifted_metrics = {}\n",
    "for rank in svd_ranks:\n",
    "    puresvd_metrics[rank] = ... # type your code here\n",
    "    shifted_metrics[rank] = ... # type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puresvd_res = pd.DataFrame.from_dict(data=puresvd_metrics, columns=['hr', 'mrr', 'cov'], orient='index')\n",
    "shifted_res = pd.DataFrame.from_dict(data=shifted_metrics, columns=['hr', 'mrr', 'cov'], orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.Series(puresvd_res['hr']).plot(label='Source', legend=True, title='HR results')\n",
    "pd.Series(shifted_res['hr']).plot(ax=ax, label='Shifted', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.Series(puresvd_res['cov']).plot(label='Source', legend=True, title='Coverage')\n",
    "pd.Series(shifted_res['cov']).plot(ax=ax, label='Shifted', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_combined = pd.concat(\n",
    "    [puresvd_res[['hr', 'cov']], shifted_res[['hr', 'cov']]],\n",
    "    keys = ['source', 'shifted'],\n",
    "    names = ['model', 'rank'],\n",
    "    axis = 0\n",
    ").reset_index()\n",
    "\n",
    "sns.scatterplot(data=metrics_combined, x='cov', y='hr', hue='model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rstest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64cd544b7330e8e73b8689d110cc075e8c836a404445c2b82c04f3ea96ea86ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
